\definecolor{exxetagray}{gray}{0.75}
\definecolor{itemcolor}{RGB}{179,217,255}
\definecolor{usercolor}{RGB}{255,204,179}

\shorthandoff{"}
\chapter{Multi-kriterielle Optimierung}
\label{ch:erweiterungen}

\section{Einführung}
\label{ch:erweiterungen:einführung}
% In den meisten Empfehlungssystemen erfolgt die Ermittlung des Nutzen einer \ac{N-E-K} anhand eines Kriteriums (z.B. der Gesamtbewertung eines Elements, Vgl. Kapitel \ref{ch:empfehlungssysteme:empfehlungserstellung:recommendation}) \cite[S. 847]{adomavicius:4:inbook}\cite[S. 745]{adomavicius:inproceedings}\cite[S. 49]{adomavicius:inproceedings:2}\cite[S. 424]{manouselis:article}\cite[S. 65]{lakiotaki:article}.
% Nach \textcite[S. 847f.]{adomavicius:4:inbook} ist diese Annahme in der Literaur zuletzt in Teilen als unzureichend bezeichnet worden.
% Es wird davon ausgegangen, dass der Nutzen eines Elements für einen Nutzer durchaus von mehreren Kriterien abhängen kann \cite[S. 847f.]{adomavicius:4:inbook}\cite[S. 424]{manouselis:article}.

In der Praxis existiert auch außerhalb des Bereichs der Empfehlungssysteme eine Vielzahl an Problemstellungen, für die unter der Berücksichtigung von oftmals konkurrierenden Kriterien eine optimale Lösung gefunden werden muss.
So zählt nach \textcite[S. ix]{statnikov:book} die Mehrheit aller Probleme der Ingenieurswissenschaft zu multi-kriteriellen Problemen.
Auch in anderen Bereichen wie dem Gesundheitswesen \cite[S. 195]{nemeth:article} oder der Marktforschung \cite[S. 50]{adomavicius:inproceedings:2} treten multi-kriterielle Probleme auf.
Ansätze für die Lösung solcher multi-kriteriellen Probleme werden allgemein unter dem Begriff der multi-kriteriellen Optimierung (engl.: multicriteria optimization) zusammengefasst \cite[S. 867]{adomavicius:4:inbook}\cite[S. v]{ehrgott:book}.
Zu bekannten Methoden zählen das Finden pareto-optimaler Lösungen \cite[S. 50]{adomavicius:inproceedings:2} und das Anwenden von Linearkombinationen zur Reduktion multi-kriterieller auf unikriterielle Probleme \cite[S. 745]{adomavicius:inproceedings}.

In der Entscheidungstheorie wird die Entscheidungsfindung in Organisationen ebenfalls als ein multi-kriterielles Problem behandelt, wobei verschiedene Aspekte wie Personal, Finanzen und Umwelt berücksichtigt werden müssen \cite[S. 50]{adomavicius:inproceedings:2}.
Ansätze, um Verantwortliche in dem Treffen von Entscheidungen anhand von (konkurrierenden) Kriterien zu unterstützen, werden gemäß \textcite[S. 50]{adomavicius:inproceedings:2} unter dem Begriff der multi-kriteriellen Entscheidungsunterstützung (engl.: \ac{MCDA}) zusammengefasst.
Outranking-Methoden zählen zu den bekanntesten Ansätzen in \ac{MCDA} \cite[S. 50]{adomavicius:inproceedings:2}.
Diese Ansätze ermöglichen es, Alternativen anhand unterschiedlicher Kriterien durch paarweise Vergleiche in Präferenz-Relation zu setzen \cite[S. 249]{bouyssou:inbook}.

Eine entscheidende Rolle in \ac{MCDA} spielt die Gewichtung der einzelnen Kriterien \cite[S. 206]{hdioud:inproceedings}\cite[S. 195]{nemeth:article}.
% Kriterien-Gewichte können entweder manuell festgelegt, oder unter dem Einsatz einer Gewicht\-ungs-Methode bestimmt werden \cite[S. 1]{vinogradova:article}.
% Das manuelle Festlegen von Gewichten umfasst Methoden, in denen Gewichte über Angaben von Stakeholdern zur Wichtigkeit der jeweiligen Kriterien bestimmt werden \cite[S. 196]{nemeth:article}.

% Wichtig ist hier eigentlich, dass die methoden noch nicht personalisiert sind, also immer nutzerübergreifend (was für uns ja eigentlich gut ist), siehe: file://wsl%24/Ubuntu/home/masc6/Projects/masterarbeit/literatur/New_Recommendation_Techniques_for_Multicriteria_Rating_Systems.pdf S. 50

\section{Bedeutung in Empfehlungssystemen}
\label{ch:erweiterungen:bedeutung}
Aus Sicht der Entscheidungstheorie \cite[S. 77]{jannach:inproceedings} können Empfehlungssysteme als entscheidungsunterstüztende Systeme verstanden werden \cite[S. 398f.]{huang:article}.
Demnach unterstützen Empfehlungssysteme die Nutzer eines Systems darin, aus einer Menge an Alternativen basierend auf mehreren Kriterien nützliche Elemente zu finden \cite[S. 398f.]{huang:article}.

Im Kontext von Empfehlungssystemen wurde der Einsatz von \ac{MCDA}-Metho\-den bereits in einigen Veröffentlichungen behandelt (siehe \cite{adomavicius:inproceedings:2}\cite{adomavicius:4:inbook}\cite{hdioud:inproceedings}\cite{lakiotaki:article}\cite{manouselis:article}\cite{zheng:inproceedings}).
\textcite[S. 849]{adomavicius:4:inbook} gehen davon aus, dass aufgrund der Generalität des Begriffs "multi-kriteriell", der multi-kriterielle Charakter \cite[S. 10]{adomavicius:5:inbook} der meisten Empfehlungssysteme auf unterschiedliche Grundideen verweisen kann.
Größtenteils können diese einer der folgenden Kategorien zugeordnet werden \cite[S. 10]{adomavicius:5:inbook}\cite[S. 849]{adomavicius:4:inbook}:
\begin{itemize}
    \item Multi-attribut-basierte Inhaltssuche, Filtern und Präferenzmodellierung
    \item Multi-objektive Empfehlungsstrategien
    \item Multi-kriterielle Bewertungen in der Präferenzerhebungen
\end{itemize}

Multi-attribut-basierte Inhaltssuche und multi-attribut-basiertes Filtern bezeichnen Systeme, die einem Nutzer ermöglichen, seine Präferenzen unter Anwendung von Such- bzw. Filterprozessen spezifizieren \cite[S. 851]{adomavicius:4:inbook}\cite[S. 10]{adomavicius:5:inbook}.
Diese zusätzlichen Präferenzen können in solchen Systemen verwendet werden, um die Menge an potenziell nützlichen Elementen für einen Nutzer weiter einzugrenzen \cite[S. 11]{adomavicius:5:inbook}.
Unter multi-attribut-basierter Präferenzmodellierung wird die Darstellung von Präferenzen anhand verschiedener Attribute eines Elements verstanden (z.b. in klassischen inhaltsbasierten \ac{RS} \cite[S. 205]{hdioud:inproceedings}) \cite[S. 10]{adomavicius:5:inbook}.
Nach \textcite[S. 850]{adomavicius:4:inbook} werden diese Arten der multi-kriteriellen Empfehlung bereits durch existierende Typen von Empfehlungssystemen unterstützt (z.B. wissenbasierten, inhaltsbasierten und hybriden \ac{RS}).
% In hybriden Empfehlungssystemen können beispielsweise Bewertungen unterschiedlicher Algorithmen über eine Linearkombination zu einem Wert kombiniert werden \cite[S. 339]{burke:article}.
Ein Beispiel stellen Conversational \ac{RS} dar, die Präferenzen eines Nutzers neben Bewertungen über aktuelle Konversationen mit einem Nutzer (z.B. in Form eines Chatbots) erschließen \cite[S. 1]{yueming:article}.
% Hier beispiel einfügen? S. 4, https://iopscience.iop.org/article/10.1088/1742-6596/930/1/012050/pdf

Als multi-objektive Empfehlungsstrategien werden Implementierungen von Empfehlungssystemen verstanden, die für die Empfehlung von Elementen für einen Nutzer mehrere Ziele (engl.: Objectives) berücksichtigen \cite[S. 850]{adomavicius:4:inbook}.
Gemäß \textcite[S. 1097]{mcnee:inproceedings} verfolgen Empfehlungssysteme in der Literatur häufig das Ziel, die Genauigkeit (engl.: Accuracy) der empfohlenen Elemente für einen Nutzer zu erhöhen.
Unter der Genauigkeit von Empfehlungen wird die Übereinstimmung einer vorhergesagten Bewertung durch das System mit der tatsächlichen Bewertung eines Nutzers verstanden \cite[S. 1098]{mcnee:inproceedings}.
In der Literatur wird davon ausgegangen, dass die Genauigkeit von Empfehlungen nicht immer ein alleiniger Indikator des tatsächlichen Nutzen von Empfehlungen ist \cite[S. 1097]{mcnee:inproceedings}\cite[S. 850]{adomavicius:4:inbook}\cite[S. 896]{adomavicius:article}.
Neben der Genauigkeit von Empfehlungen versuchen moderne Empfehlungssysteme daher oftmals die eingesetzten Algorithmen hinsichtlich weiterer Ziele (z.B. Diversität von Elementen \cite[S. 896]{adomavicius:article}, Serendipität \cite[S. 1099]{mcnee:inproceedings}) zu optimieren \cite[S. 850]{adomavicius:4:inbook}.
Multi-kriteriell bedeutet in solchen Systemen folglich die Empfehlungen für Nutzer unter Berücksichtigung mehrerer Ziele zu generieren \cite[S. 850]{adomavicius:4:inbook}.
% Beispiel?

Wird in der Literatur von multi-kriteriellen Empfehlungssystemen (engl.: \ac{MCRS}) gesprochen, wird sich zumeist auf multi-kriterielle Bewertungen in der Präferenzerhebung bezogen \cite[S. 207]{hdioud:inproceedings}\cite[S. 1156]{gupta:inproceedings}\cite[S. 327]{hassan:inproceedings}\cite[S. 2453]{zheng:inproceedings}.
Während traditionelle Empfehlungssysteme Elemente anhand eines einzigen Kriteriums (z.b. der Gesamtbewertung) bewerten, werden Elemente in \ac{MCRS} anhand mehrerer Kriterien evaluiert \cite[S. 850]{adomavicius:4:inbook}\cite[S. 2]{adomavicius:5:inbook}.
Diese multi-kriteriellen Bewertungen werden häufig in Empfehlungssystemen des kollaborativen Filterns genutzt, um komplexe Präferenzen von Nutzern abzubilden \cite[S. 850]{adomavicius:4:inbook}.
Es wird davon ausgegangen, dass diese zusätzliche Information \cite[S. 49]{adomavicius:inproceedings:2} über die Präferenzen der Nutzer die Qualität der Empfehlungen verbessern kann \cite[S. 2]{adomavicius:5:inbook}.
Im Vergleich zu multi-attribut-basierten Grundideen werden für multi-kriterielle Bewertungen keine allgemeinen Präferenzen oder Gewichte für bestimmte Attribute durch einen Nutzer angegeben \cite[S. 851]{adomavicius:4:inbook}.

% Multi-kriterielle Probleme können in Empfehlungssystemen folglich in unterschiedlichen Kontexten bestehen.
% Aufgrund eines anhaltenden Trends im Bereich der multi-kriteriellen Bewertungen, beziehen sich die meisten Veröffentlichungen zu multi-kriteriellen Empfehlungssystemen in der Literatur auf multi-kriterielle Ratings.
% Daher werden Ansätze zur Lösung multi-kriterieller Optimierungsprobleme in Empfehlungssystemen Nachfolgend werden multi-kriterielle Empfehlungssysteme im Detail betrachtet und Lösungsansätze vorgestellt.

Multi-kriterielle Bewertungen in \ac{MCRS} werden wie unikriterielle Bewertungen in traditionellen Systemen über eine Rating-Funktion $R$ abgebildet.
Werden Elemente zusätzlich zu einer Gesamtbewertung anhand weiterer Kriterien bewertet, ergibt sich für die Rating-Funktion $R$ aus Gleichung \ref{eq10} \cite[S. 853]{adomavicius:4:inbook}:
\begin{equation}\label{eq11}
    R: Nutzer \times Element \rightarrow R_{0} \times R_{1} \times ... \times R_{k}
\end{equation}
Hierbei stellt $R_{0}$ die Menge aller möglichen Gesamtbewertungen dar.\footnote{Da aus Gründen der Einfachheit in Kapitel \ref{ch:empfehlungssysteme:nutzenfunktion} für den Nutzen einer \ac{N-E-K} die Bewertung eines Nutzers für ein Element angenommen wurde, entspricht $R_{0}$ dem $Rating$ (Vgl. Gleichung \ref{eq2} und \ref{eq10}).}
$R_{i}$ bildet die Menge aller möglichen Bewertungen jedes einzelnen Kriteriums $i$ ($i=1,...,k$) ab \cite[S. 49]{adomavicius:inproceedings:2}.

Bilden \ac{MCRS} lediglich die Bewertungen der einzelnen Kriterien ab, ergibt sich für die Rating-Funktion $R$ folgende Form \cite[S. 853]{adomavicius:4:inbook}:
\begin{equation}\label{eq12}
    R: Nutzer \times Element \rightarrow R_{1} \times ... \times R_{k}
\end{equation}
Solche Systeme verfügen lediglich über Bewertungen der einzelnen Kriterien eines Elements.
Es existiert folglich keine Gesamtbewertung $R_{0}$ \cite[S. 853]{adomavicius:4:inbook}.

Tabelle \ref{tab3} bildet beispielhaft multi-kriterielle Bewertungen von Mitarbeitern eines Unternehmens für Fähigkeiten ab.
Hierbei setzt sich eine Gesamtbewertung aus dem Kenntnisstand eines Mitarbeiters und dessen Präferenzen für eine Fähigkeit zusammen.

\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{|c||c|c|c|}
    \hline
    {} & {\textbf{Java}} & {\textbf{Python}} & {\textbf{MySQL}}\\
    \hline
    \hline
    \textbf{Jane D.} & $2_{0,2}$ & $4_{3,1}$ & $2_{0,2}$ \\
    \hline
    \textbf{John D.} & $2_{1,1}$ & $4_{1,3}$ & ? \\
    \hline
    \textbf{Max M.} & $3_{2,1}$ & $3_{1,2}$ & $3_{2,1}$ \\
    \hline
    \end{tabular}
    \end{center}
    \caption[Multi-kriterielle Rating-Matrix ]{Multi-kriterielle Rating-Matrix \\
    (Eigene Darstellung in Anlehnung an \cite[S. 51]{adomavicius:inproceedings:2})}
	\label{tab3}
\end{table}

Eine alleinige Betrachtung der Gesamtbewertungen von Mitarbeitern lässt vermuten, dass der Mitarbeiter John D. am meisten Ähnlichkeit mit der Mitarbeiterin Jane D. aufweist.
Basierend auf den multi-kriteriellen Bewertungen scheint der Mitarbeiter Max M. jedoch mehr Ähnlichkeit mit John D. aufzuweisen als die Mitarbeiterin Jane D.
Es wird deutlich, dass durch die Abbildung des Nutzen eines Mitarbeiters über ein einziges Kriterium, Unterschiede bzw. Gemeinsamkeiten zwischen Nutzern unentdeckt bleiben können \cite[S. 854]{adomavicius:4:inbook}.
Durch die multi-kriteriellen Bewertungen können zusätzliche Information über die Präferenzen der Mitarbeiter des Systems abgebildet werden.
Diese können wiederum für die Vorhersage fehlender Transaktionen genutzt werden (z.B. Vorhersage von $\hat{r}_{John D., MySQL}$ anhand der Ähnlichkeit zu Max M.) \cite[S. 848]{adomavicius:4:inbook}.

Multi-kriterielle Optimierungsprobleme können in Empfehlungssystemen folglich in unterschiedlichen Kontexten bestehen.
Aufgrund eines anhaltenden Trends im Bereich der multi-kriteriellen Bewertungen \cite[S. 851]{adomavicius:4:inbook}, beziehen sich die meisten Veröffentlichungen zu Lösungsansätzen multi-kriteriel\-ler Optimierungsprobleme in der Literatur auf multi-kriterielle Ratings.
Auch wenn der Kontext der multi-kriteriellen Probleme sich unterscheiden kann, können viele Lösungsansätze in allen Bereichen eingesetzt werden.
Daher werden nachfolgend Lösungsansätze multi-kriterieller Optimierungsprobleme am Beispiel multi-kriterieller Bewertungen angeführt.

% \section{Problemstellung}

\section{Lösungsansätze}
\label{ch:erweiterungen:loesungen}
Nach \textcite[S. 853]{adomavicius:4:inbook} stellt die Integration multi-kriteriel\-ler Bewertungen in bestehende Techniken eine der wichtigsten Themen zukünftiger Empfehlungssysteme dar.
In der Literatur existieren bereits einige Veröffentlichungen, die grundlegende Techniken zur Integration multi-kriterieller Bewertungen in Empfehlungssysteme betrachten (siehe \cite{adomavicius:inproceedings:2}\cite{adomavicius:4:inbook}\cite{recommenderSystems:2016}).
Abhängig davon, in welcher Phase des Empfehlungserstellungsprozesses die Techniken eingesetzt werden, ordnen \textcite[S. 854f.]{adomavicius:4:inbook} diese einer von zwei Kategorien zu: Einsatz multi-kriterieller Bewertungen in der Vorhersage oder Einsatz multi-kriterieller Bewertungen im Ranking \cite[S. 854]{adomavicius:4:inbook}.

Während der Vorhersage-Phase können multi-kriterielle Bewertungen eingesetzt werden, um Gesamtbewertungen bzw. Bewertungen individueller Kriterien vorherzusagen \cite[S. 854]{adomavicius:4:inbook}.
Häufig werden multi-kriterielle Bewertungen für die Vorhersage in Systemen des kollaborativen Filterns verwendet \cite[S. 850]{adomavicius:4:inbook}.
Traditionell werden Techniken für die Vorhersage in Systemen des kollaborativen Filterns in modellbasierte und speicherbasierte Techniken unterschieden.
Modellbasierte Techniken verwenden Methoden der Statistik und des Maschinellen Lernens, um basierend auf historischen Daten Modelle zu entwickeln, über die fehlende Transaktionen vorhergesagt werden können.
Im Gegensatz dazu ermitteln speicherbasierte Systeme Vorhersagen "on the fly" \cite[S. 855]{adomavicius:4:inbook} basierend auf aktuell vorliegenden Daten.
Für die Vorhersage werden heuristische Methoden verwendet \cite[S. 855]{adomavicius:4:inbook}.
% Wie komme ich hier darum herum so ins detail der techniken von nachbarschaftsbasierten algorithmen zu gehen?
Abhängig davon, welche Technik für die Vorhersage angewandt wird, unterscheiden sich Lösungsansätze multi-kriterieller Bewertungen in der Vorhersage weiter in speicherbasierte- und modellbasierte Ansätze.

\subsection{Speicherbasierte Ansätze}
In speicherbasierten Systemen des kollaborativen Filterns erfolgt die Vorhersage fehlender Bewertungen grundsätzlich durch Aggregation \cite[S.738]{adomavicius:inproceedings} von Bewertungen ähnlicher Nutzer bzw. Elemente.
Dies basiert auf der Annahme, dass ähnliche Nutzer ähnliches Bewertungsverhalten aufweisen (nutzerbasiertes kollaboratives Filtern) bzw. ähnliche Elemente ähnliche Bewertungen erhalten (elementbasiertes kollaboratives Filtern) \cite[S. 29]{recommenderSystems:2016}.
In der Praxis verwenden die meisten Systeme des kollaborativen Filterns Ähnlichkeiten zwischen Nutzern für die Vorhersage fehlender Bewertungen \cite[S. 427]{recommenderSystems:2016}.
Eine Vorhersage stellt demnach eine Aggregation der Bewertungen eines Zielelements durch Nutzer dar, die (basiernd auf ihren vorherigen Bewertungen) Ähnlichkeit zu einem Zielnutzer aufweisen \cite[S.738]{adomavicius:inproceedings}.

Für die Ermittlung der Ähnlichkeit $sim(c,c')$ zweier Nutzer $c$ und $c'$, können verschiedene Ähnlichkeitsmaße herangezogen werden.
Zu den bekanntesten paarweisen Ähnlichkeitsmaßen zählen der Pearson-Korrelationskoeffizient und die Kosinus-Ähnlichkeit \cite[S. 856]{adomavicius:4:inbook}\cite[S. 738]{adomavicius:inproceedings}.
% Hier Maße mit reinnehmen oder nicht?
Sei $S(c,c')$ die Menge aller Elemente aus $S$, die beide Nutzer bewertet haben (d.h. $S(c,c')=\{s \in S | r_{cs} \neq ? \cap r_{c's} \neq ?\}$ \cite[S. 738]{adomavicius:inproceedings}), so werden die Ähnlichkeitsmaße wie folgt ermittelt \cite[S. 856]{adomavicius:4:inbook}:
\begin{itemize}
    \item Pearson-Korrelationskoeffizient:
    \begin{equation}\label{eq13}
        sim(c,c') = \frac{\sum\limits_{s \in S(c,c')}(r_{cs}-\overline{r(c)})(r_{c's}-\overline{r(c')})}{\sqrt{\sum\limits_{s \in S(c,c')}(r_{cs}-\overline{r(c)})^{2}}\sqrt{\sum\limits_{s \in S(c,c')}(r_{c's}-\overline{r(c')})^{2}}}
    \end{equation}
    \item Kosinus-Ähnlichkeit:
    \begin{equation}\label{eq14}
        sim(c,c') = \frac{\sum\limits_{s \in S(c,c')}r_{cs}r_{c's}}{\sqrt{\sum\limits_{s \in S(c,c')}r_{cs}^{2}}\sqrt{\sum\limits_{s \in S(c,c')}r_{c's}^{2}}}
    \end{equation}
\end{itemize}
Der Parameter $\overline{r(c)}$ repräsentiert die durchschnittliche Bewertung eines Nutzers $c$.

Die Idee der Integration multi-kriterieller Bewertungen in die Ähnlichkeitsberechnung besteht darin, komplexe Präferenzen der Nutzer anhand verschiedener Kriterien für die Ermittlung der Ähnlichkeit zwischen Nutzern bzw. Elementen zu nutzen \cite[S. 676]{jannach:2:article}. 
Gemäß \textcite[S. 856f.]{adomavicius:4:inbook} können Ähnlichkeitsmaße wie der Pearson-Korrelationskoeffizient oder die Kosinus-Ähnlichkeit lediglich Bewertungen anhand eines einzelnen Kriteriums verarbeiten.
In \ac{MCRS} besteht eine Bewertung $r$ jedoch neben einer Gesamtbewertung $r^{0}$ zusätzlich aus $k$ multi-kriteriellen Bewertungen $r^{1}, ..., r^{k}$, d.h. $r=(r^{0},r^{1}, ..., r^{k})$ \cite[S. 426]{recommenderSystems:2016}\cite[S. 857]{adomavicius:4:inbook}.
Anstelle eines einzigen Ratings besitzt eine \ac{N-E-K} in \ac{MCRS} demnach $k+1$ Bewertungen \cite[S. 857]{adomavicius:4:inbook}.\footnote{Für \ac{MCRS}, die keine Gesamtbewertungen beinhalten, können für die Berechnung der Ähnlichkeit dieselben Maße angewandt werden, wie für Systeme die Gesamtbewertungen verwenden, mit dem einzigen Unterschied, dass der Index $i$ nicht die Gesamtbewertung einschließt (d.h. $i \in \{1,k\}$ anstelle von $i \in \{0,k\}$) \cite[S. 857]{adomavicius:4:inbook}.}
Daher könnendie Gleichungen nicht unmittelbar für multi-kriterielle Bewertungen angewandt werden.
In Anlehnung an \textcite[S. 49]{adomavicius:inproceedings:2}, \textcite[S. 860]{adomavicius:4:inbook} und \textcite[S. 427]{recommenderSystems:2016} wird die Vorstellung der Lösungsansätze auf nutzerbasiertes kollaboratives Filtern begrenzt.\footnote{Für ein simples Vorgehen zur Umstellung der Berechnungen auf elementbasiertes kollaboratives Filtern wird auf \textcite[S. 49]{adomavicius:inproceedings:2} verwiesen.}

Ein speicherbasierter Ansatz für die Berücksichtigung multi-kriterieller Bewertungen in der Ähnlichkeitsberechnung stellt die Aggregation von Ähnlichkeiten auf Ebene der einzelnen Kriterien dar.
Gibt $sim^{i}(c,c')$ die Ähnlichkeit zweier Nutzer $c$ und $c'$ für jedes Kriterium $i \in \{0,k\}$ an, so kann deren Ähnlichkeit nach \textcite[S. 427]{recommenderSystems:2016} allgemein in zwei Schritten ermittelt werden:
\begin{enumerate}
    \item Berechnung der Ähnlichkeit $sim^{i}(c,c')$ für jedes Kriterium $i \in \{0,k\}$ anhand eines paarweisen Ähnlichkeitsmaßes (z.B. Pearson-Korrelations\-koeffizient, Kosinus-Ähnlichkeit).
    \item Berechnung der aggregierten Ähnlichkeit $sim^{aggr}(c,c')$ anhand einer Aggregationsfunktion über alle Ähnlichkeiten der einzlenen Kriterien:
    \begin{equation}
        sim^{aggr}(c,c') = F(sim^{0}(c,c'), sim^{1}(c,c'), ..., sim^{k}(c,c'))
    \end{equation}
\end{enumerate}

Nach \textcite[S. 427]{recommenderSystems:2016} und \textcite[S. 857]{adomavicius:4:inbook} zählen zu den bekanntesten Aggregationsfunktionen multi-kriterieller Bewertungen:
\begin{itemize}
    \item die durchschnittliche Ähnlichkeit:
    \begin{equation}\label{eq15}
        sim^{aggr}(c,c') = \frac{\sum\limits_{i=0}^{k}sim^{i}(c,c')}{k+1}
    \end{equation}
    \item die pessimistische Ähnlichkeit:
    \begin{equation}\label{eq16}
        sim^{aggr}(c,c') = \underset{i=0,...,k}{\min}\textnormal{ }sim^{i}(c,c')
    \end{equation}
    \item sowie die gewichtete Ähnlichkeit:
    \begin{equation}\label{eq17}
        sim^{aggr}(c,c') = \sum\limits_{i=0}^{k}w^{i}sim^{i}(c,c')
    \end{equation}
\end{itemize}

Die durchschnittliche Ähnlichkeit wird ermittelt, indem die Summe der Ähnlichkeiten der einzelnen Kriterien durch die Anzahl der Kriterien plus Gesamtbewertung $k+1$ geteilt wird.
Für die pessimistische Ähnlichkeit wird aus allen Ähnlichkeiten der einzelnen Kriterien (inkl. Gesamtbewertung) die kleinstse Ähnlichkeit bestimmt \cite[S. 427]{recommenderSystems:2016}.
Die gewichtete Ähnlichkeit multikriterieller Bewertungen \cite[Kapitel 6.1 The Algorithm, Abs. 1ff.]{tang:article} stellt eine Verallgemeinerung der durchschnittlichen Ähnlichkeit dar \cite[S. 427]{recommenderSystems:2016}.
Hierbei stellt $w^{i}$ das Gewicht des Kriteriums $i$ $(i=0,...,k)$ dar, welches nach \textcite[S. 857]{adomavicius:4:inbook} angibt, wie wichtig ein Kriterium für eine Empfehlung ist.
Die Werte der Gewichte können gemäß \textcite[S. 428]{recommenderSystems:2016} mithilfe herkömmlicher Parameteroptimierungs-Techniken (z.b. Kreuzvalidierung) bestimmt werden.

Neben der Ähnlichkeitsberechnung mit anschließender Aggregation kann die Ähnlichkeit zweier Nutzer unter Berücksichtigung multi-kriterieller Bewertungen auch über multidimensionale Distanzmaße ermittelt werden \cite[S. 857]{adomavicius:4:inbook}.
Für diesen speicherbasierten Ansatz wird im ersten Schritt die Ähnlichkeit zweier Nutzer $c$ und $c'$ anhand eines Elements $s$ über ein herkömmliches Distanzmaß ermittelt.
% Hier Maße mit reinnehmen oder nicht?
Zu bekannten Distanzmaßen zählen \textcite[S. 857f.]{adomavicius:4:inbook}:
\begin{itemize}
    \item die Manhattan-Distanz:
    \begin{equation}\label{eq18}
        elementDist^{aggr}(c,c',s)= \sum\limits_{i=0}^{k}|r_{cs}^{i}-r_{c's}^{i}|
    \end{equation}
    \item sowie die Euklidische Distanz:
    \begin{equation}\label{eq19}
        elementDist^{aggr}(c,c',s)= \sqrt{\sum\limits_{i=0}^{k}(|r_{cs}^{i}-r_{c's}^{i}|)^{2}}
    \end{equation}
\end{itemize}

Nach \textcite[S. 240]{sahoo:article} berücksichtigen diese Distanzmaße nicht mögliche Abhängigkeiten (Korrelationen) zwischen den einzelnen Kriterien (inkl. Gesamtbewertung).
Abhängigkeiten können bedeuten, dass nicht jedes Bewertungskriterium gänzlich neue Information über die Präferenzen eines Nutzers liefert, sondern ein Kriterium beispielsweise stärkeren Einfluss auf die Ausprägung der Bewertungen der anderen Kriterien haben kann \cite[S. 235]{sahoo:article}.\footnote{In der Psychometrie ist dieser Effekt als der Halo-Effekt bekannt \cite[S. 3]{sahoo:2:article}.}
Ein multidimensionales Distanzmaß, welches Abhängigkeiten zwischen Kriterien berücksichtigt ist die Mahalanobis-Distanz.
Dieses Maß ermittelt die Distanz zwischen zwei Vektoren $\vec{c}$ und $\vec{c'}$ unter Einbezug der Kovarianz-Matrix $V$:
\begin{equation}\label{eq25}
    elementDist^{aggr}(\vec{c},\vec{c'}) = \sqrt{(\vec{c}-\vec{c'})^{T}V^{-1}(\vec{c}-\vec{c'})}
\end{equation}
Hierbei stellt ein Vektor die muti-kriteriellen Bewertungen eines Elements $s$ durch einen Nutzer dar.
Die Kovarianz-Matrix ermitteln \textcite[S. 240]{sahoo:article} basierend auf historsichen Daten zu Bewertungen der Nutzer.

Die Gesamtdistanz zweier Nutzer $c$ und $c'$ wird, unabhängig von der Wahl des Distanzmaßes, als Durchschnitt über alle Elemente in $S(c,c')$ ermittelt, d.h. für alle Elemente, die beide Nutzer bewertet haben \cite[S. 858]{adomavicius:4:inbook}:
\begin{equation}\label{eq20}
    dist^{aggr}(c,c')= \frac{\sum\limits_{s \in S(c,c')}elementDist^{aggr}(c,c',s)}{|S(c,c')|}
\end{equation}

Aus der Gesamtdistanz lässt sich die Ähnlichkeit zweier Nutzer wie folgt ableiten \cite[S. 858]{adomavicius:4:inbook}:
\begin{equation}\label{eq21}
    sim^{aggr}(c,c') = \frac{1}{1 + dist^{aggr}(c,c')}
\end{equation}

Speicherbasierte Ansätze adjustieren lediglich die Ähnlichkeitsberechnung in kollaborativen Systemen.\footnote{Die speicherbasierten Ansätze werden daher auch als ähnlichkeitsbasierte Ansätze bezeichnet \cite[S. 52]{adomavicius:inproceedings:2}.}
Das bedeutet, fehlende Bewertungen können nach Ermittlung der Ähnlichkeit wie gewohnt mittels Aggregation (z.B. gewichtete Summe \cite[S. 859]{adomavicius:4:inbook}) bestimmt werden \cite[S. 52]{adomavicius:inproceedings:2}\cite[S. 428]{recommenderSystems:2016}.

\subsection{Modellbasierte Ansätze}
Im Vergleich zu speicherbasierten Algorithmen des kollaborativen Filterns werden fehlende Bewertungen in traditionellen modellbasierten Systemen über Vorhersage-Modelle bestimmt \cite[S. 861]{recommenderSystems:2016}.
Basierend auf vergangenen Bewertungen der Nutzer eines Systems \cite[S. 358]{jin:article}, werden diese Vorhersage-Modelle im Vorfeld entwickelt (bspw. anhand von statistischen Modellen) \cite[S. 71]{recommenderSystems:2016}.
In der Literatur existieren bereits einige Ansätze für die Integration multi-kriterieller Bewertungen in modellbasierte Systeme \cite[S. 861]{adomavicius:4:inbook}.
Eine umfassende Übersicht grundlegender Ansätze stellen \textcite[S. 861]{adomavicius:4:inbook} vor.

\textbf{Aggregation Function Ansatz}
Nach \textcite[S. 861]{adomavicius:4:inbook} besteht ein Nachteil speicherbasierter Ansätze darin, dass sich deren Einsatz auf Systeme des kollaborativen Filterns beschränkt.
Ein alternativer Ansatz, der in Kombination mit jeglicher Art an Empfehlungssystem verwendet werden kann, stellt der Aggregation Function Ansatz von \textcite[S. 52ff.]{adomavicius:inproceedings:2} dar \cite[S. 861]{adomavicius:4:inbook}.
Dem Ansatz liegt die Idee zugrunde, dass Gesamtbewertungen von Elementen eine Kombination (Aggregation) ihrer zugehörigen multi-kriteriellen Bewertungen darstellen \cite[S. 861]{adomavicius:4:inbook}.
Gemäß \textcite[S. 52]{adomavicius:inproceedings:2} wird eine Gesamtbewertung $r^{0}$ durch eine Aggregationfunktion $f$ ihrer multikriteriellen Bewertungen $r^{1}, ..., r^{k}$ repräsentiert:
\begin{equation}\label{eq22}
    r^{0} = f(r^{1}, ..., r^{k})
\end{equation}
Das bedeutet, der Aggregation Function Ansatz unterstellt eine bestimmte Beziehung zwischen der Gesamtbewertung eines Elements durch einen Nutzer und dessen multi-kriterieller Bewertungen \cite[S. 52]{adomavicius:inproceedings:2}.
So kann es sein, dass die Präferenz von Mitarbeitern für Fähigkeiten eine stärkere Priorität besitzt, d.h. das die meisten Mitarbeiter Fähigkeiten tatsächlich hoch bewerten, wenn sie diese gleichzeitig präferieren (Vgl. Tabelle \ref{tab3}).
Nach dieser Annahme müsste eine hoch vorhergesagte Präferenz eines Mitarbeiters für eine Fähigkeit ebenfalls in einer hoch vorhergesagten Gesamtbewertung resultieren \cite[S. 52]{adomavicius:inproceedings:2}.

Die Vorhersage von Gesamtbewertungen nach dem Aggregation Function Ansatz erfolgt anhand von drei Schritten, welche nachfolgend in Abbildung \ref{fig:optimierung:loesungen:abb1} grafisch abgebildet sind.

\begin{figure}[H]
    \centering
	\includegraphics[width=1.0\textwidth]{gfx/a-f-ansatz.png}
	\caption[Aggregation Function Ansatz]{Aggregation Function Ansatz\\
    (Eigene Darstellung in Anlehnung an \cite[S. 862]{adomavicius:4:inbook})}
	\label{fig:optimierung:loesungen:abb1}
\end{figure}

Im ersten Schritt wird die $k$-dimensionale Rating-Matrix in $k$ unikriterielle Rating-Matrizen der traditionellen Form (Nutzer$\times$Element-Matrix) aufgeteilt \cite[S. 53]{adomavicius:inproceedings:2}.
Für jedes Kriterium $i \in {1,...,k}$ wird daraufhin unter Anwendung eines beliebigen Algorithmus (z.B.: kollaboratives Filtern, inhaltsbasierte Algorithmen) dessen fehlende Bewertungen vorhergesagt \cite[S. 428]{recommenderSystems:2016}.
Dadurch wird das $k$-dimensionale multi-kriterielle Problem in $k$ unikriterielle Probleme zerlegt \cite[S. 861]{adomavicius:4:inbook}.
Schritt 2 umfasst das Aufstellen der Aggregatios-Funktion $f$.
Nach \textcite[S. 53]{adomavicius:inproceedings:2} existieren hierfür maßgeblich drei Verfahren:
\begin{itemize}
    \item \textit{Domänenwissen:} Aufstellen der Funktion basierend auf Erfahrungen und Domänenwissen. Ein simpler Ansatz stellt der Durchschnitt aller angenommenen Bewertungen der einzelnen Kriterien als Aggregationsfunktion dar.
    \item \textit{Statistische Methoden:} Aufstellen der Funktion anhand statistischer Verfahren (z.B. lineare und nicht-lineare Regressionsanalysen) \cite[S. 53]{adomavicius:inproceedings:2}. So kann die Vorhersage einer Gesamtbewertung in der linearen Regression als eine Linearkombination der (angenommenen) multi-kriteriellen Bewertungen repräsentiert werden \cite[S. 429]{recommenderSystems:2016}:
    \begin{equation}\label{eq23}
        \hat{r}^{0} = \sum\limits_{i=1}^{k}w^{i} r^{i}
    \end{equation}
    Die Gewichte $w^{1}, ..., w^{k}$ der Kriterien können anhand verschiedener Techniken der linearen Regression bestimmt werden \cite[S. 429]{recommenderSystems:2016}.
    \item \textit{Techniken des Maschinellen Lernens:} Aufstellen der Funktion über Modelle des Maschinellen Lernens (z.B. neuronale Netze) \cite[S. 53]{adomavicius:inproceedings:2}.
\end{itemize}
Weiter unterscheiden \textcite[S. 53]{adomavicius:inproceedings:2} Aggregations-Funk\-tionen in Abhängigkeit ihres Bezugs.
Wird eine Funktion verwendet um Vorhersagen für alle \ac{N-E-K}-en übergreifend zu treffen, wird diese als total Aggregation Function bezeichnet (d.h. Gewichte sind nutzer- bzw. elementübergreifend festgesetzt).
Als nutzerbasiert bzw. elementbasiert wird eine Aggregationsfunktion bezeichnet, die basierend auf Bewertungen eines einzelnen Nutzers bzw. Elements bestimmt wird.
Dies kann in Domänen sinnvoll sein, in denen sich die Gewichte einzelner Kriterien zwischen Nutzern bzw. Elementen stark unterscheiden \cite[S. 53]{adomavicius:inproceedings:2}.

Im letzten Schritt erfolgt die Vorhersage der Gesamtbewertungen basierend auf den (angenommenen) multi-kriteriellen Bewertungen und der erstellten Aggregationsfunktion $f$ \cite[S. 861]{adomavicius:4:inbook}.

\textbf{Probabilistic Modeling Ansatz}
Neben dem Aggregation Function Ansatz nennen \textcite[S. 861]{adomavicius:4:inbook} probabilistische Modellierungs-Ansätze (engl.: Probabilistic Modeling Approach) für die Integration multi-kriterieller Bewertungen in Empfehlungssysteme.
Vereinfacht gesehen handelt es sich dabei um Methoden, die mit Wahrscheinlichkeitsverteilungen für die Vorhersage von Bewertungen arbeiten.
\textcite[S. 861]{adomavicius:4:inbook} nennen als Beispiel die Veröffentlichung von \textcite[S. 231]{sahoo:article}.
In der Veröffentlichung wird eine Anpassung des \ac{FMM} von \textcite[S. 704ff.]{si:inproceedings} um multi-krierielle Bewertungen vorgestellt.

\textcite[S. 358]{jin:article} beschreiben das \ac{FMM} als eine grafische Darstellung eines probabilistischen Modells, in dem Nutzer und Elemente (mehreren)\footnote{Das \ac{FMM} unterscheidet sich von herkömmlichen grafischen Modellen unter anderem darin, dass Nutzer bzw. Elemente mehreren Clustern zugeordnet werden können \cite[S. 3]{si:inproceedings}\cite[S. 366]{jin:article}.} Clustern (übergeordneten Klassen) zugeordnet werden können.
Die Idee hinter probabilistischen Clustering-Methoden besteht darin, zugrundeliegende (auch: latente) Strukturen aus einer Menge an Daten zu ermitteln \cite[S. 197]{truyen:inproceedings}, die für die Vorhersage verwendet werden.
Das \ac{FMM} folgt der Annahme, dass eine Bewertung r, welche ein Element s von einem Nutzer c erhält, von einer latenten Variable $Z_{c}$ und einer latenten Variable $Z_{s}$ abhängt \cite[S. 235]{sahoo:article}.
$Z_{c}$ kennzeichnet hierbei die Klasse(n), denen ein Nutzer $c$ und ${Z_{s}}$ die Klasse(n), denen ein Element $s$ zugeordnet werden kann \cite[S. 862]{adomavicius:4:inbook}\cite[S. 3]{si:inproceedings}.
% Die Idee des \ac{FMM} besteht darin, dass die Variablen Bewertung, Nutzer und Element unter der Bedingung der latenten Variablen $Z_{c}$ und $Z_{s}$ unabhängig voneinander sind \cite[S. 4]{sahoo:2:article}\cite[S. 235]{sahoo:article}.
% Die Wahrscheinlichkeit der Bewertung $r$ eines Nutzers $c$ für ein Element $s$ ergibt sich demnach aus der Summe aller Wahrscheinlichkeiten der Kombinationen der Variablen $Z_{c}$ und $Z_{s}$ \cite[S. 862]{adomavicius:4:inbook}:
% \begin{equation}\label{eq24}
%     P(c,s,r) = \sum\limits_{Z_{c}, Z_{s}}P(Z_{c})P(Z_{s})P(c|Z_{c})P(s|Z_{s})P(r|Z_{c},Z_{s})
% \end{equation}
Das grundlegende Modell ist in Abbildung \ref{fig:optimierung:loesungen:abb2:1} dargestellt, wobei die latenten Variablen grau hinterlegt sind.
% Mixture Models sind grafische Darstellungen probabilistischer Modelle, in denen Nutzer bzw. Elemente in Empfehlungssystemen in Clustern zusammengefasst werden und in Verbindung mit Bewertungen gesetzt werden können.
% Dadurch kann die Ähnlichkeit von Nutzern anhand deren Bewertung eines Element-Clusters erfolgenbasieren und nicht auf Ratings eines einzelnen Elements.
% Mixture Models wurden ursprünglich entwickelt, um das Sparsity-Problem zu umgehen.
% Vereinfacht gesagt ist eine Bewertung r abhängig von einer Nutzerklasse und einer Elementklasse und nicht genau von einem Nutzer und einem Element.

\begin{figure}[H]
    \centering
    \subfloat[Flexible Mixture Model]{\includegraphics[width=2.0in]{gfx/f-m-m.png}\label{fig:optimierung:loesungen:abb2:1}}
    \subfloat[Flexible Mixture Model mit multi-kriteriellen Bewertungen und Dependency-Struktur]{\includegraphics[width=3.0in]{gfx/f-m-m-2.png}\label{fig:optimierung:loesungen:abb2:2}}\\
  \caption[Beispiel eines probabilistischen Modellierungs-Ansatzes]{Beispiel eines probabilistischen Modellierungs-Ansatzes\\
	(Eigene Darstellung in Anlehnung an \cite[S. 836]{adomavicius:4:inbook})}\label{fig:optimierung:loesungen:abb2}
\end{figure}

\textcite[S. 235]{sahoo:article} erweitern das \ac{FMM} um multi-kriterielle Bewertungen.
Hierbei unterstellen \textcite[S. 236f.]{sahoo:article} zusätzlich eine strukturelle Abhängigkeit zwischen den Bewertungen der einzelnen Kriterien (inkl. Gesamtbewertung).
Nach \textcite[S. 236f.]{sahoo:article} besteht die stärkste Abhängigkeit (durchschnittliche Korrelation) zwischen der Gesamtbewertung eines Elements und den Bewertungen der einzelnen Kriterien.
Die Gesamtbewertung eines Elements hat folglich den größten Einfluss auf die Bewertung der einzelnen Kriterien des Elements.
Daraus schließen \textcite[S. 236f.]{sahoo:article}, dass alle Kriterien, unter der Bedingung der Gesamtbewertung, unabhängig voneinander sind.
Die Abhängigkeiten (engl.: Dependencies) zwischen den Kriterien bilden \textcite[S. 235]{sahoo:article} in Anlehnung an Dependence Trees von \textcite[S. 463]{chow:article} in einer Baumstruktur ab.
Die Integration multi-kriterieller Bewertungen in das ursprüngliche \ac{FMM} in Form einer Dependency Structure ist in Abbildung \ref{fig:optimierung:loesungen:abb2:2} grafisch dargestellt.

Die Wahrscheinlichkeit der Bewertung eines Nutzers für ein Element ergibt sich demnach aus der Summe aller Wahrscheinlichkeiten der Kombinationen der Variablen $Z_{c}$ und $Z_{s}$, unter Einbezug der Abhängigkeiten einzelner Kriterien von der Gesamtbewertung.
% Für die Wahrscheinlichkeit einer Bewertung $\vec{r}$ (Vektor der Gesamtbewertung zzgl. Bewertungen der einzelnen Kriterien) eines Element $s$ durch einen Nutzer $c$ ergibt sich daher \cite[S. 244]{sahoo:article}:
% \begin{equation}\label{eq26}
%     P(c,s,\vec{r}) = \sum\limits_{Z_{c}, Z_{s}}P(Z_{c})P(Z_{s})P(c|Z_{c})P(s|Z_{s})\prod\limits_{i=0}^{k} P(r^{i}|Z_{c},Z_{s}, Pa_{r^{i}})
% \end{equation}
% Hierbei kennzeichnet $Pa_{r^{i}}$ den Knoten, von dem eine Variable $r^{i}$ abhängt, d.h. nach \textcite[S. 236]{sahoo:article} die Gesamtbewertung.
% Ein Vergleich der beiden Gleichungen \ref{eq24} und \ref{eq26} zeigt, dass sich lediglich die Wahrscheinlichkeit einer Bewertung in Abhängigkeit der latenten Variablen geändert hat.
% Anstelle der Wahrscheinlichkeit $P(r|Z_{c},Z_{s})$ steht das Produkt der Wahrscheinlichkeiten der Bewertung der einzelnen Kriteriums eines Elements einer Klasse durch einen Nutzer einer Klasse, unter Berücksichtigung der Gesamtbewertung ($P(r^{i}|Z_{c},Z_{s}, Pa_{r^{i}})$).

Die Parameter ($Z_{c}$ und $Z_{s}$ \cite[S. 4]{si:inproceedings}) des \ac{FMM} können mithilfe des Expectation Maximization Algorithmus von \textcite[S. 1ff.]{dempster:article} bestimmt \cite[S. 863]{adomavicius:4:inbook}.
Unter Anwendung der Parameter kann eine fehlende Bewertung als die Bewertung mit der höchsten Wahrscheinlichkeit vorhergesagt \cite[S. 863]{adomavicius:4:inbook}. 

% Einen weiteren probabilistischen Ansatz zur Integration multi-kriterieller Bewertungen in die Vorhersage führen \textcite[S. 97ff.]{zhang:article} an.
% Im Detail stellen die Autoren zwei multi-kriterielle Herangehensweisen vor, welche auf der Probabilistic Latent Semantic Analysis aufbauen \cite[S. 864]{adomavicius:4:inbook}.
% Die Probabilistic Latent Semantic Analysis \cite[S. 89ff.]{hofmann:article} ist ein statistisches Konzept, das ebenfalls ein Vorhandensein latenter Variablen unterstellt.
% Im Vergleich zum \ac{FMM} existiert in der Probabilistic Latent Semantic Analysis nur ein Set $Z$ an latenten Variablen \cite[S. 2]{si:inproceedings}.
% Jede Kombination von Nutzer und Element kann einer Klasse $z \in Z=\{z_{1},...,z_{q}\}$ zugeordnet werden \cite[S. 51]{hofmann:inproceedings}.
% Das bedeutet, Nutzer und Elemente werden einem Cluster $z$ zugeordnet.
% Daraus resultiert nach \textcite[S. 94]{hofmann:article}, dass Nutzer und Elemente, unter der Bedingung $Z$, unabhängig voneinander sind.
% Die Wahrscheinlichkeit einer Kombination aus Nutzer und Element lässt sich daher in Abhängigkeit von $Z$ wie folgt bestimmen \cite[S. 51]{hofmann:inproceedings}:
% \begin{equation}\label{eq27}
%     P(c,s) = \sum\limits_{z \in Z}P(z)P(c|z)P(s|z)
% \end{equation}

% Checken wie ich Zugriff auf das Paper bekomme: https://dl.acm.org/doi/10.5555/1574514.1574517

\textbf{Multi-linear Singular Value Decomposition Ansatz}
Als \ac{MSVD} Ansatz bezeichnen \textcite[S. 864]{adomavicius:4:inbook} einen weiteren modellbasierten Ansatz für die Integration multi-kriterieller Bewertungen in Empfehlungssysteme.
Dieser Ansatz stellt eine Realisation der Matrix Factorization in \ac{MCRS} dar \cite[S. 864]{adomavicius:4:inbook}.\footnote{"[...] realization of the Matrix Factorization approach in multi-criteria rating settings." - \cite[S. 864]{adomavicius:4:inbook}}
Nach \textcite[S. 94]{recommenderSystems:2016} ist Matrix Factorization die Repräsentation einer $m \times n$-Matrix $R$ als Produkt einer $m \times k$-Matrix $U$ und einer $n \times k$-Matrix $V$ \cite[S. 94]{recommenderSystems:2016}.
Die Matrix $U$ des Produkts bildet $k$ latente Vektoren ab, welche die Affinität von Nutzern für $k$ Kategorien (Faktoren) von Elementen beinhalten.
Entsprechend stellt Matrix $V$ $k$ latenten Vektoren der Elemente dar, welche die Affinität von Elementen für diese Kategorien abbilden \cite[S. 94]{recommenderSystems:2016}.

\ac{SVD} ist eine bekannte \cite[S. 83]{koren:inbook} Matrix Factorization Technik.
Gemäß \textcite[S. 864]{adomavicius:4:inbook} wird \ac{SVD} maßgeblich für das Auffinden von Faktor-Räumen geringerer Dimensionalität (bspw. $k < n$) angewandt.
Anhand der vollständigen latenten Vektoren können Bewertungen in Empfehlungssystemen ermittelt werden.
Stellt ein Vektor $p_{c}$ die Affinität eines Nutzers für $k$ Faktoren der Elemente eines Systems dar und $p_{s}$ die Affinität eines Elements für diese Kategorien $k$, so kann eine Bewertung wie folgt ermittelt werden \cite[S. 865]{adomavicius:4:inbook}:
\begin{equation}\label{eq29}
    \hat{r}_{cs} = p_{c}^{T}p_{s}
\end{equation}
Für eine ausführlichere Beschreibung der \ac{SVD} wird auf \textcite[S. 234ff.]{amatriain:inbook} verwiesen.

Die grundsätzlich anhand zweidimensionaler Matrizen ($Nutzer \times Element$) durchgeführte \ac{SVD}, kann für multidimensionale Matrizen erweitert werden \cite[S. 865]{adomavicius:4:inbook}.
Diese Technik wird als \ac{MSVD} bezeichnet \cite[S. 865]{adomavicius:4:inbook}.
Für den \ac{MSVD} Ansatz werden multi-kriterielle Bewertungen, in Anlehnung an die Darstellung dreidimensionaler Daten in multidimensionalen Systemen\footnote{Vgl. Kapitel \ref{ch:empfehlungssysteme:preferences:data}}, in einem $Nutzer \times Element \times Kriterien$-Tensor abgebildet \cite[S. 1235]{li:2:inproceedings}.
Als Beispiel nennen \textcite[S. 865]{adomavicius:4:inbook} die Veröffentlichung von \textcite[S. 1235ff.]{li:2:inproceedings}.
Die Autoren wenden die truncated \ac{MSVD} an, um die Dimensionalität des $Nutzer \times Element \times Kriterien$-Tensors zu reduzieren \cite[S. 865]{adomavicius:4:inbook}.\footnote{Eine detaillierte Vorgehensweise für die Dimensionsreduktion kann \textcite[S. 6f]{ruble:article} entnommen werden.}
Basierend auf dem näherungsweisen Tensor, wenden \textcite[S. 1236]{li:2:inproceedings} Techniken des kollaborativen Filterns an, um Empfehlungen zu ermitteln.

\textbf{Support Vector Regression Ansatz}
Unter dem Aggregation Function Ansatz wurden bereits einige Methoden für die Bestimmung von Aggregationsfunktionen vorgestellt (z.B. Lineare Regression).
Ansätze, die für die Bestimmung einer Aggregationsfunktion die \ac{SVR} \cite[S. 155ff.]{drucker:inproceedings} anwenden, bezeichnen \textcite[S. 865]{adomavicius:4:inbook} gesondert als \ac{SVR} Ansatz.

Wie bei herkömmlichen Regressionsmodellen wird mittels \ac{SVR} eine Funktion $f$ ermittelt, die den Zusammenhang zwischen einer Input-Variable $x$ und deren abhängigen Output-Variable $y$ modelliert.
Herkömmliche Regressionsmodelle wie die Lineare Regression ermitteln Regressionsgleichungen beispielsweise, indem sie versuchen den quadrierten Abstand zwischen vorhergesagtem und tatsächlichem Wert für $y$ zu minimieren.
Im Gegensatz dazu ermittelt \ac{SVR} eine Funktion $f$ unter Anwendung des $\epsilon$-insensitive Ansatzes von \textcite[S. 181]{vapnik:book} \cite[S. 67]{awad:inbook}.
Dieser führt einen $\epsilon$-insensitiven, symmetrischen Bereich mit minimalem Radius um $f$ ein, sodass Fehler $< \epsilon$ nicht das Erstellen der Regressionsgleichung beeinflussen \cite[S. 67]{awad:inbook}.
Für ein besseres Verständnis ist in Abbildung \ref{fig:optimierung:loesungen:abb3} ein Beispiel einer linearen \ac{SVR} dargestellt.

\begin{figure}[H]
    \centering
	\includegraphics[width=1.0\textwidth]{gfx/svr.png}
	\caption[Lineare Support Vector Regression]{Lineare Support Vector Regression \cite[S. 68]{awad:inbook}}
	\label{fig:optimierung:loesungen:abb3}
\end{figure}

Der Bereich um $f$ wird durch die Stützvektoren (engl.: Support Vectors) bestimmt, welche die äußersten Punkte einer Datenmenge darstellen.
Ein Parameter $\xi$ legt fest, wie viele Datenpunkte außerhalb des Bereichs toleriert werden \cite[S. 70]{awad:inbook}.

Gemäß \textcite[S. 675]{jannach:2:article} kann über die \ac{SVR} eine Aggregationsfunktion erlernt werden, die den Zusammenhang zwischen einer Gesamtbewertung und einzelnen Kriterien beschreibt. 

Nach \textcite[S. 866]{adomavicius:4:inbook} stellen die Ansätze erste Anhaltspunkte für die Integration multi-kriterieller Bewertungen in die Vorhersage dar.
Nachfolgend werden in Anlehnung an \textcite[S. 867]{adomavicius:4:inbook} Ansätze vorgestellt, die nach der Vorhersage ansetzen, das heißt, wenn Bewertungen für \ac{N-E-K} vollständig vorliegen.

% Hier noch neue Gliederung der Ansätze?

Für das Ranking von Elementen anhand multipler Kriterien wird unterschieden, ob Gesamtbewertungen vorliegen, oder das Ranking über die multi-kriteriellen Bewertungen bestimmt wird \cite[S. 867]{adomavicius:4:inbook}.
Liegt eine Gesamtbewertung vor, erfolgt das Ranking typischerweise analog zu traditionellen Systemen, die auf unikriteriellen Bewertungen basieren.
Das bedeutet, nach der Vorhersage wird die (angenommene) Gesamtbewertung einer \ac{N-E-K} als Sortier-Kriterium für das Ranking von Elementen herangezogen \cite[S. 867]{adomavicius:4:inbook}.

Ohne Gesamtbewertung wird das Ranking von Elementen komplexer \cite[S. 867]{adomavicius:4:inbook}.
Dem liegt zugrunde, dass die Ordnung der einzelnen Kriterien nicht unmittelbar ersichtlich \cite[S. 867]{adomavicius:4:inbook} oder ohne Weiteres über Aggregationsfunktionen erlernbar ist.
Basierend auf Verfahren der multi-kriteriellen Optimierung aus dem Bereich Operations Research \cite[S. 745]{adomavicius:inproceedings} stellen \textcite[S. 867]{adomavicius:4:inbook} verschiedene Methoden für das Ranking von Elementen anhand multipler Kriterien vor.
Hierzu zählen
\begin{itemize}
    \item Verfahren für das Finden Pareto-optimaler Lösungen,
    \item Aggregation mittels Linear-Kombination und Domänenwissen über Ordnung von Elementen, sowie
    \item Verwendung multi-kriterieller Bewertungen als Filterkriterien für Empfehlungen.
\end{itemize}

Für das Experiment dieser Arbeit wird von einer Gesamtbewertung für \ac{N-E-K} ausgegangen.
Daher wird auf die ausführliche Betrachtung multi-kriterieller Bewertungen für das Ranking von Elementen nachfolgend verzichtet.
Für eine detaillierte Übersicht der einzelnen Ansätze wird auf \textcite[S. 745]{adomavicius:inproceedings} und \textcite[S. 868ff.]{adomavicius:4:inbook} verwiesen.

\shorthandon{"}